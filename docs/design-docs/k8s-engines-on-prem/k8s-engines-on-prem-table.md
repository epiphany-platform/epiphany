# ON-PREM KUBERNETES AUTOMATION RESEARCH RESULTS IN COMPARISON TABLE

definitions:
- "offline mode": an Epiphany-style offline mode, which provides and serves all system packages (rpm, deb), all docker images and all other extra files
- "airgapped mode": provides and serves all docker images that are required for running Kubernetes cluster (this removes the need for pulling from external registries)

| Feature              | RKE2                 | RKE2 - description   | RKE                  | RKE - description    | Epiphany             | Epiphany - description | Kubespray            | Kubespray - description | Kubeone              | Kubeone - description |
| -------------------- | -------------------- | -------------------- | -------------------- | -------------------- | -------------------- | ---------------------- | -------------------- | ----------------------- | -------------------- | --------------------- |
| Opensource project | :white_check_mark: | - https://github.com/rancher/rke2 | :white_check_mark: | - https://github.com/rancher/rke | :white_check_mark: | - https://github.com/epiphany-platform/epiphany | :white_check_mark: | - https://github.com/kubernetes-sigs/kubespray | :white_check_mark: | - https://github.com/kubermatic/kubeone |
| License | - Apache License 2.0 | - https://github.com/rancher/rke2/blob/master/LICENSE | - Apache License 2.0 | - https://github.com/rancher/rke/blob/master/LICENSE | - Apache License 2.0 | - https://github.com/epiphany-platform/epiphany/blob/develop/LICENSE | - Apache License 2.0 | - https://github.com/kubernetes-sigs/kubespray/blob/master/LICENSE | - Apache License 2.0 | - https://github.com/kubermatic/kubeone/blob/master/LICENSE |
| Multiplatform support | :x: | - Linux (Intel/AMD)  | :white_check_mark: | - Linux (Intel/AMD), Linux (ARM 32-bit), Linux (ARM 64-bit) | :x: | - Linux (Intel/AMD) | :white_check_mark: | - Linux (Intel/AMD), Linux (ARM 32-bit), Linux (ARM 64-bit) | :white_check_mark: | - Linux (Intel/AMD), Linux (ARM 64-bit) |
| Upscale worker and control plane nodes | :white_check_mark: | - It is possible to join new control plane and worker nodes manually | :white_check_mark: | - Possible to scale up contol plane and worker nodes. It is necessary to just add nodes to config file and execute 'rke up' | :white_check_mark: | - Possible to scale up contol plane and worker nodes. It is necessary to add new nodes to config file, switch some flags and execute 'epicli apply' | :white_check_mark: | - Possible to scale up contol plane and worker nodes. It is necessary to add new nodes to config file and execute 'ansible-playbook'<br /> - https://kubespray.io/#/docs/nodes | :x: | - No informations how to do it on prem |
| Downscale worker and control plane nodes | :x: | - | :white_check_mark: | - Possible to scale down contol plane and worker nodes. It is necessary to remove nodes from config file and execute 'rke up' | :x: | - | :white_check_mark: | - Possible to scale down contol plane and worker nodes. It is necessary to remove nodes from config file and execute 'ansible-playbook'<br /> - https://kubespray.io/#/docs/nodes | :x: | - No informations how to do it on prem |
| Installation approach | Hypercube | - Single binary file which install all core components as pods or it is also possible to run RKE2 as systemd service.<br /> - Necessary to execute the installation process (run binary file or systemd service) manually on every node :warning: and some manual steps in order to join new nodes to cluster. Similar approach as in the "classic" kubeadm installation process. Possible to determine installation method: rpm or tar<br /> - Installs all required system packages automatically with one exception : containerd must be pre-installed on all nodes :warning:<br /> - Own solution for setting up a cluster based on the GO language<br /> - There is no manifest config file | Hypercube | - Single binary file which contains all set of core Kubernetes components, e.g. API, Scheduler, Controller, etc. The problem with this approach is that bug-fix for API causes update of all core Kubernetes containers. Only single endpoint to download the binary. Kubernetes components as Docker containers - also kubelet.<br /> - Installs all required system packages automatically with one exception : docker-ce must be pre-installed on all nodes :warning:<br /> - Own solution for setting up a cluster based on the GO language<br /> - Based on manifest config file | Kubeadm | - Based on python and ansible tool, uses kubeadm<br /> - Based on manifest config file  | Kubeadm | - Can be managed using pre-built docker images form quay.io, ansible based<br /> - Installs all required system packages automatically<br /> - Based on manifest config file   | Kubeadm | - Installed from a single statically-linked binary, based on Ansible and Kubeadm<br /> - Installs all required system packages automatically<br /> - Based on manifest config file  |
| Support Single Node mode | :white_check_mark: | - | :white_check_mark: | - | :white_check_mark: | - | :white_check_mark: | - | :white_check_mark: | - |
| Support HA-mode | :white_check_mark: | - https://docs.rke2.io/install/ha/ <br /> - Necessary to add stable endpoint in front of the server nodes with fixed registration address | :white_check_mark: | - https://rancher.com/docs/rancher/v2.x/en/installation/resources/k8s-tutorials/ha-rke/<br /> - By default the kubelets and kube-proxies are configured to connect to nginx-proxy service that proxies all requests to all master nodes | :white_check_mark: | - https://github.com/epiphany-platform/epiphany/blob/develop/docs/design-docs/kubernetes-ha/kubernetes-ha.md<br /> - Based on idea from kubespray HA-mode, on every node lightweight load-balancer is installed that proxies all requests to all master nodes | :white_check_mark: | - On every non master node lightweight load-balancer (nginx proxy) is installed that proxies all requests to all master nodes | :white_check_mark: | - Very poorly documented. Only master components are configured out of the box in HA mode, in order to achieve full high availability we should apply manually a similar solution as in Epiphany |
| Possible container runtimes | :white_check_mark: | - Containerd | :white_check_mark: | - Docker | :white_check_mark: | - Docker | :white_check_mark: | - Docker (default), containerd, cri-o | :white_check_mark: | - Docker (default), containerd<br /> - It's expected that the Docker support will be removed in Kubernetes 1.22 :warning: |
| Cluster state file | :x: | - | :white_check_mark: | - State file is created by default what can be very useful in case of module approach | :x: | - | :x: | - | :x: | - |
| Kubeconfig extracted automatically | :x: | - | :white_check_mark: | - Kubeconfig is automatically generated for the RKE cluster in local directory | :x: | - Only for installation process | :x: | - | :white_check_mark: | - Kubeconfig is automatically generated for the Kubeone cluster in local directory |
| Up-to-date K8s version | :white_check_mark: | - The latest version of K8s with a slight delay | :white_check_mark: | - The latest version of K8s with a slight delay | :x: | - Usually two minor version behind the upstream version | :white_check_mark: | - The latest version of K8s with a slight delay | :x: | - Usually two minor version behind the upstream version |
| Certificate Management | :white_check_mark: | - Default certificates are valid for 1 year<br /> - The certificates are rotated when RKE2 is restarted (if the certificates are expired or have fewer than 90 days remaining before they expire) | :white_check_mark: | - Default certificates are valid for 10 years<br /> - Possible to use custom certificates<br /> - RKE has a 'rke cert' command and it is possible to easily rotate the certificates | :white_check_mark: | - Default certificates are valid for one year (possible to set custom value)<br /> - Possible to use custom CA certificates<br /> - Epiphany has a ability to renew the certificates | :white_check_mark: | - Certficates are valid by default for one year<br />  - There is no official possibility to use custom certificate<br /> - Kubespray supports rotating certificates used for etcd and Kubernetes components, but some manual steps may be required<br /> - https://kubespray.io/#/docs/upgrades?id=upgrade-considerations | :white_check_mark: | - Certficates are valid by default for one year<br /> - It is not officially documented but certificates are renew during cluster upgrade<br /> - There is no official possibility to use custom certificate |
| Offline mode | :x: | - Airgapped supported, offline not fully supported, we need to provide private Docker registry or use tarball method (the required docker images can be very easily downloaded and used during installation) | :x: | - Airgapped supported, offline not fully supported, we need to provide private Docker registry and the list of required docker images can be easily obtained | :white_check_mark: | - | :x: | - Not fully supported / automated<br /> - Docker images and binary files (kubeadm, kubectl, ...) can be downloaded automatically<br /> - Download procedure requires exising 2-node online cluster :warning:<br /> - Download procedure fails if there is no "/etc/kubernetes/" folder present on the machines<br /> - User needs to provide on-prem docker-registry and http server<br /> - https://kubespray.io/#/docs/offline-environment | :x: | - Not fully supported / automated<br /> - Provides a script to download docker images<br /> - User needs to provide on-prem docker-registry <br /> - User needs to take care of system packages<br /> - https://docs.kubermatic.com/kubermatic/v2.14/advanced/offline_mode/ |
| How fast is the upgrade? | :white_check_mark: | - ~60% faster upgrade than in Epiphany<br /> - Very stable :white_check_mark: <br /> - The upgrade must be done manually :warning: node by node, but it is possible to finish the upgrade on 3 master nodes and 3 worker nodes configuration in similar time to Kubespray upgrade process  | :white_check_mark: | - ~100% faster upgrade than in Epiphany<br /> - Very stable :white_check_mark: <br />  - Comparison made on the basis of cluster with 3 master nodes in HA-mode and 3 worker nodes  | :x: | - ~100% longer upgrade than in RKE<br /> - Comparison made on the basis of cluster with 3 master nodes in HA-mode and 3 worker nodes using custom repository feature. Without using the feature, the process is even much more longer (2-3 times). | :white_check_mark: | - ~60% faster upgrade than in Epiphany<br /> - Occasional failures <br /> - Comparison made on the basis of cluster with 3 master nodes in HA-mode and 3 worker nodes | :white_check_mark: | - ~70% faster upgrade than in Epiphany<br /> - Stable on KVM<br /> - Comparison made on the basis of cluster with 3 master nodes in HA-mode and 3 worker nodes |
| How fast is the installation? | :white_check_mark: | - ~60% faster installation than in Epiphany<br /> - Very stable :white_check_mark: <br /> - The installation must be done manually :warning: node by node, but it is possible to finish the installation on 3 master nodes and 3 worker nodes configuration in similar time to Kubespray installation process | :white_check_mark: | - ~100% faster installation than in Epiphany<br /> - Very stable :white_check_mark: <br /> - Comparison made on the basis of cluster with 3 master nodes in HA-mode and 3 worker nodes | :x: | - ~100% longer installation than in RKE<br /> - Comparison made on the basis of cluster with 3 master nodes in HA-mode and 3 worker nodes using custom repository feature. Without using the feature, the process is even much more longer (2-3 times). | :white_check_mark: | - ~60% faster installation than in Epiphany<br /> - Occasional failures<br /> - Comparison made on the basis of cluster with 3 master nodes in HA-mode and 3 worker nodes | :white_check_mark: | - ~70% faster installation than in Epiphany<br /> - It was not possible to install on Azure online, failed repeatedly :warning:, stable on KVM<br /> - Comparison made on the basis of cluster with 3 master nodes in HA-mode and 3 worker nodes |
| Zero downtime upgrade | :white_check_mark: | - Only when the cluster requirements are meet: https://docs.rke2.io/upgrade/basic_upgrade/<br /> - Necessary to upgrade node by node manually :warning: using installation script or binary file | :white_check_mark: | - Only when the cluster requirements are meet: https://rancher.com/docs/rke/latest/en/upgrades/maintaining-availability/#2-cluster-requirements | :white_check_mark: | - Only when the cluster requirements are meet: https://github.com/epiphany-platform/epiphany/blob/develop/docs/home/howto/UPGRADE.md | :white_check_mark: | - Using ansible upgrade playbook and only when the cluster requirements are meet, check graceful upgrade: https://kubespray.io/#/docs/upgrades | :white_check_mark: | - Only when the cluster requirements are meet, upgrade is processing node by node in place, more: https://docs.kubermatic.com/kubeone/v1.0/upgrading/ | 
| CNI network plugin supported | :white_check_mark: | - Canal | :white_check_mark: | - Canal (default), Flannel, Calico, Weave | :white_check_mark: | - Flannel (default), Calico, Canal | :white_check_mark: | - Calico (default), canal, cilium, flannel, kube-ovn, kube-router, macvlan, ovn4nfv, weave | :white_check_mark: | - Canal (default), weave |
| Cost | :x: | - High - lots of code needs to be added and automated in order to have the epiphany features  | :white_check_mark: | - Low - all of the features which are in Epiphany are already well implemented and ready to use on production | :x: | - High - Epiphany team needs to mantain all the code and upgrades | :white_check_mark: | - Medium - almost all of the features which are in Epiphany are already implemented but there are still a lot of code which could be improved and added | :x: | - High - lots of code needs to be added and improved in order to have the epiphany features |
| CNCF Certification | :white_check_mark: | - Every release supports the same APIs as upstream Kubernetes | :white_check_mark: | - Every release supports the same APIs as upstream Kubernetes | :x: | - Epiphany is only based on Kubeadm which has CNCF Certification. Every release supports the same APIs as upstream Kubernetes | :white_check_mark: | - Every release supports the same APIs as upstream Kubernetes | :white_check_mark: | - Every release supports the same APIs as upstream Kubernetes |
| Installation is idempotent | :x: | - | :white_check_mark: | - | :white_check_mark: | - | :x: | - Lots of idempotency issues reported | :white_check_mark: | - https://github.com/kubermatic/kubeone/pull/663 |
| Hardening and Security | :white_check_mark: | - FIPS 140-2 support :warning:<br />- Network plugin requirements done by default ( IP forwarding, bridge-nf-call tables etc..)<br /> - Admission-plugins enabled by default but only 'NodeRestriction,PodSecurityPolicy'<br /> - Audit logs disabled by default<br /> - All the defaults of kubernetes services can be changed using additional arguments in 'rke2 server' command | :white_check_mark: | - Network plugin requirements done by default ( IP forwarding, bridge-nf-call tables etc..)<br /> - Admission-plugins enabled by default<br /> - Audit logs enabled by default<br /> - All the defaults of kubernetes services can be changed using the extra_args in config file. | :white_check_mark: | - All the hardening (IP forwarding, bridge-nf-call tables etc..) is done by default and mantain by Epiphany Team using usually ansible modules<br /> - Audit logs enabled by default<br /> - Admission-plugins enabled by default<br /> - All the defaults of kubernetes services can be changed using parameters in config file, if no we can add the possibility. | :x: | - Network plugin requirements done by default ( IP forwarding, bridge-nf-call tables etc..)<br /> - Admission-plugins enabled by default but there are still some of them which should be added in manifest file<br /> - Audit logs disabled by default<br /> - Lots of the defaults of kubernetes services can be changed using manifest files but there are still some parameters which are not configurable in manifest config file | :x: | - Network plugin requirements done by default ( IP forwarding, bridge-nf-call tables etc..)<br /> - Admission-plugins enabled by default but there are still some of them which should be added in manifest file<br /> - Audit logs disabled by default<br /> - Lots of the defaults of kubernetes services can be changed using manifest files but there are still some parameters which are not configurable in manifest config file |
| DNS providers | :white_check_mark: | - CoreDNS or none<br /> - Host plugin not added by default<br /> - Deployed as addon<br /> - Any Kubernetes manifests found in '/var/lib/rancher/rke2/server/manifests' will automatically be deployed to RKE2, so it is possible to customize the packaged CoreDNS configuration creating the manifest config file | :white_check_mark: | - CoreDNS as default but possible to use kube-dns<br /> - Host plugin not added by default<br /> - Possible to use custom addons :warning: | :white_check_mark: | - CoreDNS as default<br />  - Config map is updated by default with host plugin using ansible and kubectl | :white_check_mark: | - CoreDNS by default, possible to use: CoreDNS Dual mode, Manual mode or none<br /> - Host plugin is not added by default | :white_check_mark: | - CoreDNS as default <br /> - Possible to use custom addons :warning: |
| Encrypting Secret Data at Rest | :white_check_mark: | - Enabled by default, can be easily disabled | :white_check_mark: | - Disabled by default but it can be enabled easily | :white_check_mark: | - Enabled by default, can be easily disabled | :white_check_mark: | - Disabled by default, can be easily enabled | :x: | - Disabled by default, not configurable |
| Cluster backups and disaster recovery | :white_check_mark: | - Snapshots are enabled by default and scheduled<br /> - Snapshots are always saved only locally<br /> - Easy to restore cluster from backup using 'rke2 server' command with additional arguments | :white_check_mark: | - Can be configured to automatically take snapshots of etcd<br /> - Restore can be done using 'rke etcd snapshot-restore' command <br /> - Snapshots are always saved locally in '/opt/rke/etcd-snapshots' <br /> - Possible to upload snapshots to Amazon S3 backend | :white_check_mark: | - Can be done using 'epicli backup' command<br /> - Default backup location is defined on repository host<br /> - Possible backend storage for snapshots: Azure Blob Storage, Amazon S3, NAS and any other attached storage<br /> - Restore can be done using 'epicli recovery' command | :x: | - Very poorly documented, but looking at the code it can be possible to run manually ready to use ansible playbook and save etcd backup locally, nothing more | :white_check_mark: | - Backup is possible to do automaticaly to AWS S3 bucket using backup addon, recovery process must be done manually |
| Built-in Helm support | :white_check_mark: | - Based on Helm Controller that manages Helm charts using a Helm Chart Custom Resource Definition (CRD) which are built-in. | :x: | - | :white_check_mark: | - Based on helm command-line tool | :white_check_mark: | - Disabled by default but can be enabled easily, based on helm command-line tool | :x: | - |
| Maintenance | :white_check_mark: | - 23 contributors<br /> Last month:<br /> - 6 authors of commits<br /> - 13 active PR<br /> - 11 merged PR<br /> - 6 releases | :white_check_mark: | - 73 contributors<br /> Last month:<br /> - 8 authors of commits<br /> - 32 active PR<br /> - 26 merged PR<br /> - 13 releases | :white_check_mark: | - 23 contributors<br /> Last month:<br /> - 6 authors of commits<br /> - 36 active PR<br /> - 29 merged PR<br /> - 1 release | :white_check_mark: | - 702 contributors<br /> Last month:<br /> - 26 authors of commits<br /> - 86 active PR<br /> - 75 merged PR<br /> - 1 release | :white_check_mark: | - 36 contributors<br /> Last month:<br /> - 3 authors of commits<br /> - 9 active PR<br /> - 6 merged PR<br /> - 1 release |
| Troubleshooting | :white_check_mark: | - No activity in Stack Overflow community<br /> - 108 open issues in github repository<br /> Last month:<br /> - 32 active issues<br /> - 11 closed issues | :white_check_mark: | - 104 search result with 'RKE' in Stack Overflow community<br /> - 153 open issues in github repository<br /> Last month:<br /> - 24 active issues<br /> - 14 closed issues | :white_check_mark: | - No activity in Stack Overflow community<br /> - 298 open issues in github repository<br /> Last month:<br /> - 43 active issues<br /> - 18 closed issues | :white_check_mark: | - 374 search result with 'Kubespray' in Stack Overflow community<br /> - 142 open issues in github repository<br /> Last month:<br /> - 85 active issues<br /> - 57 closed issues | :white_check_mark: | - No activity in Stack Overflow community<br /> - 42 open issues in github repository<br /> Last month:<br /> - 24 active issues<br /> - 12 closed issues |
| Documentation | :white_check_mark: | - Human friendly but a few topics are not covered, must be improved<br /> - https://docs.rke2.io/ | :white_check_mark: | - Human friendly and well documented <br /> - Easy to find all necessary information<br /> - https://rancher.com/docs/rke/latest/en/ | :white_check_mark: | - Need to be improved<br /> - Almost all necessary topics are covered <br /> - All the documentation in .md files in github repository<br /> - Already created task for the improvment<br /> - https://github.com/epiphany-platform/epiphany | :white_check_mark: | - Human friendly documentation but a lot of inaccurate informations, need to be still improved<br /> - https://kubespray.io/#/ | :white_check_mark: | - No examples documented for on-prem installation, a lot of important topics are not covered<br /> - The least valuable documentation :warning:<br /> - https://docs.kubermatic.com/kubeone/master/ |
